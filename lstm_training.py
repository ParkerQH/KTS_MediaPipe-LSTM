import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
X = np.load('mediaPipe/pose_X.npy')   # shape: (ìƒ˜í”Œìˆ˜, 99)
y = np.load('mediaPipe/pose_Y.npy')   # shape: (ìƒ˜í”Œìˆ˜,)

# 2. LSTM ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜ (ì‹œí€€ìŠ¤ ê¸¸ì´=1)
X = X.reshape(-1, 1, 99)    # (ìƒ˜í”Œìˆ˜, 1, 99)

# 3. ë¼ë²¨ ì›-í•« ì¸ì½”ë”©
y_cat = to_categorical(y)   # (ìƒ˜í”Œìˆ˜, í´ë˜ìŠ¤ìˆ˜)

# 4. í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
X_train, X_val, y_train, y_val = train_test_split(X, y_cat, test_size=0.2, random_state=42)

# 5. LSTM ëª¨ë¸ ì„¤ê³„
model = Sequential([
    LSTM(32, input_shape=(1, 99)),
    Dense(16, activation='relu'),
    Dense(y_cat.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# 6. ëª¨ë¸ í•™ìŠµ
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=16,
    validation_data=(X_val, y_val)
)

# 7. ëª¨ë¸ ì €ì¥
model.save('lstm_model/kickboard_lstm_model.keras')  # ì›í•˜ëŠ” íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥

# 8. ëª¨ë¸ í‰ê°€
loss, acc = model.evaluate(X_val, y_val)
print(f'ê²€ì¦ ì •í™•ë„: {acc:.4f}')

# âœ… F1-score ë° ë¶„ë¥˜ ë¦¬í¬íŠ¸ ì¶”ê°€
from sklearn.metrics import classification_report, f1_score

# í™•ë¥  â†’ í´ë˜ìŠ¤ ì˜ˆì¸¡
y_pred_probs = model.predict(X_val)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_val, axis=1)

# F1-score ë° ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥
report = classification_report(y_true, y_pred, digits=4)
print("ğŸ“Š Classification Report:\n", report)

# F1-scoreë§Œ ë”°ë¡œ ì¶œë ¥ (weighted í‰ê·  ê¸°ì¤€)
f1 = f1_score(y_true, y_pred, average='weighted')
print(f"F1-score (weighted): {f1:.4f}")